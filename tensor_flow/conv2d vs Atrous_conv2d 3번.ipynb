{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_np = np.arange(1,10).reshape(3,3,1,1).astype(np.float32)\n",
    "input_np = np.arange(1,17).reshape(1,4,4,1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_input\n",
      " [[ 1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.]\n",
      " [ 9. 10. 11. 12.]\n",
      " [13. 14. 15. 16.]]\n",
      "_filter\n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "_output\n",
      " [[111. 178. 217. 145.]\n",
      " [231. 348. 393. 252.]\n",
      " [363. 528. 573. 360.]\n",
      " [197. 274. 295. 175.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "filter = tf.Variable(filter_np)\n",
    "input = tf.Variable(input_np)\n",
    "output = tf.nn.conv2d(input, filter, [1,1,1,1], 'SAME')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    _input, _filter, _output = sess.run([input, filter, output])\n",
    "    _input = np.squeeze(_input)\n",
    "    _filter = np.squeeze(_filter)\n",
    "    _output = np.squeeze(_output)\n",
    "\n",
    "print('_input\\n',_input)\n",
    "print('_filter\\n',_filter)\n",
    "print('_output\\n',_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_input\n",
      " [[ 1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.]\n",
      " [ 9. 10. 11. 12.]\n",
      " [13. 14. 15. 16.]]\n",
      "_filter\n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "_output\n",
      " [[194. 222. 170. 194.]\n",
      " [306. 334. 266. 290.]\n",
      " [122. 138.  98. 110.]\n",
      " [186. 202. 146. 158.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "filter = tf.Variable(filter_np)\n",
    "input = tf.Variable(input_np)\n",
    "output = tf.nn.atrous_conv2d(input, filter, 2, 'SAME')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    _input, _filter, _output = sess.run([input, filter, output])\n",
    "    _input = np.squeeze(_input)\n",
    "    _filter = np.squeeze(_filter)\n",
    "    _output = np.squeeze(_output)\n",
    "\n",
    "print('_input\\n',_input)\n",
    "print('_filter\\n',_filter)\n",
    "print('_output\\n',_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_input\n",
      " [[ 1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.]\n",
      " [ 9. 10. 11. 12.]\n",
      " [13. 14. 15. 16.]]\n",
      "_filter\n",
      " [[1. 0. 2. 0. 3.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [4. 0. 5. 0. 6.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [7. 0. 8. 0. 9.]]\n",
      "_output\n",
      " [[ 5. 10. 15. 20.]\n",
      " [25. 30. 35. 40.]\n",
      " [45. 50. 55. 60.]\n",
      " [65. 70. 75. 80.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "new_filter = np.zeros([5,5,1,1,]).astype(np.float32)\n",
    "new_filter[0::2,0::2,:,:] = filter_np\n",
    "\n",
    "\n",
    "filter = tf.Variable(new_filter)\n",
    "input = tf.Variable(input_np)\n",
    "output = tf.nn.atrous_conv2d(input, filter, 2, 'SAME')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    _input, _filter, _output = sess.run([input, filter, output])\n",
    "    _input = np.squeeze(_input)\n",
    "    _filter = np.squeeze(_filter)\n",
    "    _output = np.squeeze(_output)\n",
    "\n",
    "print('_input\\n',_input)\n",
    "print('_filter\\n',_filter)\n",
    "print('_output\\n',_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_input\n",
      " [[ 1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.]\n",
      " [ 9. 10. 11. 12.]\n",
      " [13. 14. 15. 16.]]\n",
      "_filter\n",
      " [[1. 0. 0. 2. 0. 0. 3.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [4. 0. 0. 5. 0. 0. 6.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [7. 0. 0. 8. 0. 0. 9.]]\n",
      "_output\n",
      " [[277. 122. 135. 243.]\n",
      " [ 73.  30.  35.  60.]\n",
      " [117.  50.  55.  96.]\n",
      " [175.  74.  81. 141.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "new_filter = np.zeros([7,7,1,1,]).astype(np.float32)\n",
    "new_filter[0::3,0::3,:,:] = filter_np\n",
    "filter = tf.Variable(new_filter)\n",
    "input = tf.Variable(input_np)\n",
    "output = tf.nn.conv2d(input, filter, [1,1,1,1], 'SAME')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    _input, _filter, _output = sess.run([input, filter, output])\n",
    "    _input = np.squeeze(_input)\n",
    "    _filter = np.squeeze(_filter)\n",
    "    _output = np.squeeze(_output)\n",
    "\n",
    "print('_input\\n',_input)\n",
    "print('_filter\\n',_filter)\n",
    "print('_output\\n',_output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_input\n",
      " [[ 1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.]\n",
      " [ 9. 10. 11. 12.]\n",
      " [13. 14. 15. 16.]]\n",
      "_filter\n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "_output\n",
      " [[277. 122. 135. 243.]\n",
      " [ 73.  30.  35.  60.]\n",
      " [117.  50.  55.  96.]\n",
      " [175.  74.  81. 141.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "filter = tf.Variable(filter_np)\n",
    "input = tf.Variable(input_np)\n",
    "output = tf.nn.conv2d(input, filter, [1,1,1,1], 'SAME', dilations=[1,3,3,1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    _input, _filter, _output = sess.run([input, filter, output])\n",
    "    _input = np.squeeze(_input)\n",
    "    _filter = np.squeeze(_filter)\n",
    "    _output = np.squeeze(_output)\n",
    "\n",
    "print('_input\\n',_input)\n",
    "print('_filter\\n',_filter)\n",
    "print('_output\\n',_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## atrous_conv2d_transpose vs conv2d_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_input\n",
      " [[ 1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.]\n",
      " [ 9. 10. 11. 12.]\n",
      " [13. 14. 15. 16.]]\n",
      "_filter\n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "_output\n",
      " [[ 29.  62.  83.  75.]\n",
      " [ 99. 192. 237. 198.]\n",
      " [207. 372. 417. 330.]\n",
      " [263. 446. 485. 365.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "filter = tf.Variable(filter_np)\n",
    "input = tf.Variable(input_np)\n",
    "output = tf.nn.atrous_conv2d_transpose(input,filter,[1,4,4,1],1,'SAME')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    _input, _filter, _output = sess.run([input, filter, output])\n",
    "    _input = np.squeeze(_input)\n",
    "    _filter = np.squeeze(_filter)\n",
    "    _output = np.squeeze(_output)\n",
    "\n",
    "print('_input\\n',_input)\n",
    "print('_filter\\n',_filter)\n",
    "print('_output\\n',_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_input\n",
      " [[ 1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.]\n",
      " [ 9. 10. 11. 12.]\n",
      " [13. 14. 15. 16.]]\n",
      "_filter\n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "_output\n",
      " [[ 46.  58.  70.  86.]\n",
      " [ 94. 106. 134. 150.]\n",
      " [118. 142. 142. 170.]\n",
      " [214. 238. 254. 282.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "filter = tf.Variable(filter_np)\n",
    "input = tf.Variable(input_np)\n",
    "output = tf.nn.atrous_conv2d_transpose(input,filter,[1,4,4,1],2,'SAME')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    _input, _filter, _output = sess.run([input, filter, output])\n",
    "    _input = np.squeeze(_input)\n",
    "    _filter = np.squeeze(_filter)\n",
    "    _output = np.squeeze(_output)\n",
    "\n",
    "print('_input\\n',_input)\n",
    "print('_filter\\n',_filter)\n",
    "print('_output\\n',_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_input\n",
      " [[ 1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.]\n",
      " [ 9. 10. 11. 12.]\n",
      " [13. 14. 15. 16.]]\n",
      "_filter\n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "_output\n",
      " [[ 29.  62.  83.  75.]\n",
      " [ 99. 192. 237. 198.]\n",
      " [207. 372. 417. 330.]\n",
      " [263. 446. 485. 365.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "newfilter = np.zeros([5,5,1,1]).astype(np.float32)\n",
    "newfilter[::2,::2,:,:] = filter_np\n",
    "\n",
    "filter = tf.Variable(filter_np)\n",
    "\n",
    "input = tf.Variable(input_np)\n",
    "output = tf.nn.atrous_conv2d_transpose(input,filter,[1,4,4,1],1,'SAME')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    _input, _filter, _output = sess.run([input, filter, output])\n",
    "    _input = np.squeeze(_input)\n",
    "    _filter = np.squeeze(_filter)\n",
    "    _output = np.squeeze(_output)\n",
    "\n",
    "print('_input\\n',_input)\n",
    "print('_filter\\n',_filter)\n",
    "print('_output\\n',_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_input\n",
      " [[ 1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.]\n",
      " [ 9. 10. 11. 12.]\n",
      " [13. 14. 15. 16.]]\n",
      "_filter\n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "_output\n",
      " [[111. 178. 217. 145.]\n",
      " [231. 348. 393. 252.]\n",
      " [363. 528. 573. 360.]\n",
      " [197. 274. 295. 175.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "newfilter = np.zeros([5,5,1,1]).astype(np.float32)\n",
    "newfilter[::2,::2,:,:] = filter_np[::-1,::-1,:,:]\n",
    "\n",
    "filter = tf.Variable(filter_np)\n",
    "\n",
    "input = tf.Variable(input_np)\n",
    "output = tf.nn.conv2d(input,filter,[1,1,1,1],'SAME')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    _input, _filter, _output = sess.run([input, filter, output])\n",
    "    _input = np.squeeze(_input)\n",
    "    _filter = np.squeeze(_filter)\n",
    "    _output = np.squeeze(_output)\n",
    "\n",
    "print('_input\\n',_input)\n",
    "print('_filter\\n',_filter)\n",
    "print('_output\\n',_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
